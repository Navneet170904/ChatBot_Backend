{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "2CNjPlk6qNm8"
      },
      "outputs": [],
      "source": [
        "# !pip install -q -U google-generativeai\n",
        "# !pip install googlesearch-python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "aJjRL1fnulQO"
      },
      "outputs": [],
      "source": [
        "import google.generativeai as genai\n",
        "from googlesearch import search\n",
        "import webbrowser\n",
        "import pywhatkit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "JZub-z8BxlcY"
      },
      "outputs": [],
      "source": [
        "GOOGLE_API_KEY=\"AIzaSyCiWVvjpAy6huRyUK5TzSAcQiUepvePcN4\"\n",
        "\n",
        "genai.configure(api_key=GOOGLE_API_KEY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "id": "igkUPVbDxt0M",
        "outputId": "25237462-1c10-4603-fc1e-ee75c887498f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "models/gemini-1.0-pro-latest\n",
            "models/gemini-1.0-pro\n",
            "models/gemini-pro\n",
            "models/gemini-1.0-pro-001\n",
            "models/gemini-1.0-pro-vision-latest\n",
            "models/gemini-pro-vision\n",
            "models/gemini-1.5-pro-latest\n",
            "models/gemini-1.5-pro-001\n",
            "models/gemini-1.5-pro-002\n",
            "models/gemini-1.5-pro\n",
            "models/gemini-1.5-pro-exp-0801\n",
            "models/gemini-1.5-pro-exp-0827\n",
            "models/gemini-1.5-flash-latest\n",
            "models/gemini-1.5-flash-001\n",
            "models/gemini-1.5-flash-001-tuning\n",
            "models/gemini-1.5-flash\n",
            "models/gemini-1.5-flash-exp-0827\n",
            "models/gemini-1.5-flash-002\n",
            "models/gemini-1.5-flash-8b\n",
            "models/gemini-1.5-flash-8b-001\n",
            "models/gemini-1.5-flash-8b-latest\n",
            "models/gemini-1.5-flash-8b-exp-0827\n",
            "models/gemini-1.5-flash-8b-exp-0924\n",
            "models/gemini-2.0-flash-exp\n",
            "models/gemini-exp-1206\n",
            "models/gemini-exp-1121\n",
            "models/gemini-exp-1114\n",
            "models/gemini-2.0-flash-thinking-exp\n",
            "models/gemini-2.0-flash-thinking-exp-1219\n",
            "models/learnlm-1.5-pro-experimental\n"
          ]
        }
      ],
      "source": [
        "for m in genai.list_models():\n",
        "  if 'generateContent' in m.supported_generation_methods:\n",
        "    print(m.name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "d8vb2ZyZxwIc"
      },
      "outputs": [],
      "source": [
        "model = genai.GenerativeModel('gemini-pro')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c-AY7OJt4Hte",
        "outputId": "ef5fc168-82e9-4296-e959-bdedcebd1900"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ChatSession(\n",
              "    model=genai.GenerativeModel(\n",
              "        model_name='models/gemini-pro',\n",
              "        generation_config={},\n",
              "        safety_settings={},\n",
              "        tools=None,\n",
              "        system_instruction=None,\n",
              "        cached_content=None\n",
              "    ),\n",
              "    history=[]\n",
              ")"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chat = model.start_chat(history=[])\n",
        "chat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Z4u-xQQnxz1f"
      },
      "outputs": [],
      "source": [
        "def generate_content(text):\n",
        "  response = model.generate_content(text)\n",
        "  print(\"Bot : \", response.text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "_oKr9xD837h5"
      },
      "outputs": [],
      "source": [
        "def response(text):\n",
        "  response = chat.send_message(text)\n",
        "  print(\"Bot : \", response.text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "c6f5WK1sKEt1"
      },
      "outputs": [],
      "source": [
        "def browse(url):\n",
        "   webbrowser.open_new(url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "W57D2J_xS2YJ"
      },
      "outputs": [],
      "source": [
        "def play_on_youtube(query):\n",
        "  query = query.split(\"play \")[1]\n",
        "  query = query.split(\" on youtube\")[0]\n",
        "  print(f\"Playing {query} on youtube.....\")\n",
        "  pywhatkit.playonyt(query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "# def search_on_youtube(query):\n",
        "#     query = query.split(\"search on youtube for \")[1]\n",
        "#     print(f\"Searching {query} on youtube.....\")\n",
        "#     webbrowser(query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "nUyjn2Cv6zF7"
      },
      "outputs": [],
      "source": [
        "def search_on_google(text):\n",
        "  search_term = text.split(\"search for \")[1] if \"search for \" in text else text\n",
        "  print(f\"Searching Google for : {search_term}\")\n",
        "  top_result = list(search(search_term, advanced=True))\n",
        "  print(f\"Site URL : {top_result[0].url}\")\n",
        "  print(f\"Title : {top_result[0].title}\")\n",
        "  print(f\"Description : {top_result[0].description}\")\n",
        "\n",
        "  show = input(\"Would you like me to show you the results on web? [yes/no] : \")\n",
        "  if(show==\"yes\"):\n",
        "    browse(top_result[0].url)\n",
        "  else:\n",
        "    return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "exguBMh24LXR",
        "outputId": "4514baf1-cd29-4064-a3ed-809879699627"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Playing kala chasma on youtube.....\n"
          ]
        }
      ],
      "source": [
        "while True:\n",
        "  user_input = input(\"User : \")\n",
        "  user_input = user_input.lower()\n",
        "\n",
        "  if (user_input==\"stop\" or user_input==\"exit\"):\n",
        "    break\n",
        "\n",
        "  elif ((\"write\" in user_input) or (\"generate\" in user_input) or (\"create\" in user_input)):\n",
        "    generate_content(user_input)\n",
        "\n",
        "  elif \"search\" in user_input:\n",
        "    search_on_google(user_input)\n",
        "\n",
        "  elif (\"youtube\" in user_input) or (\"play\" in user_input):\n",
        "    play_on_youtube(user_input)\n",
        "    break\n",
        "\n",
        "  else:\n",
        "    response(user_input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YH-rStkeyHC-",
        "outputId": "a5665c3f-4bdb-437b-e29f-3586179890e7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[parts {\n",
              "   text: \"hi my name is navneet\"\n",
              " }\n",
              " role: \"user\",\n",
              " parts {\n",
              "   text: \"Hello Navneet! It\\'s nice to meet you. I am an AI assistant, and I\\'m here to help you with any questions or tasks you may have. Is there anything I can assist you with today?\"\n",
              " }\n",
              " role: \"model\"]"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chat.history"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
